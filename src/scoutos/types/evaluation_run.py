# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

import pydantic
from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.unchecked_base_model import UncheckedBaseModel
from .evaluation_config_output import EvaluationConfigOutput
from .evaluation_metrics import EvaluationMetrics
from .evaluation_run_status import EvaluationRunStatus
from .test_result import TestResult


class EvaluationRun(UncheckedBaseModel):
    """
    Evaluation run entity stored in PostgreSQL.

    Represents a complete evaluation execution with all test results and metrics.
    Summary metrics stored in evaluation_runs table, detailed results in cloud storage.

    Can be created from:
    1. A saved Evaluation (has evaluation_id)
    2. Ephemeral config (evaluation_id is None)
    """

    id: str = pydantic.Field()
    """
    Unique evaluation run ID
    """

    evaluation_id: typing.Optional[str] = pydantic.Field(default=None)
    """
    ID of saved evaluation if run from one
    """

    evaluation_name: typing.Optional[str] = pydantic.Field(default=None)
    """
    Denormalized name for convenience
    """

    config: EvaluationConfigOutput = pydantic.Field()
    """
    Evaluation configuration used (snapshot)
    """

    test_count: int = pydantic.Field()
    """
    Total number of test cases
    """

    status: EvaluationRunStatus = pydantic.Field()
    """
    Execution status
    """

    metrics: typing.Optional[EvaluationMetrics] = pydantic.Field(default=None)
    """
    Summary metrics (pass_count, fail_count, etc.) for querying
    """

    results: typing.Optional[typing.List[TestResult]] = pydantic.Field(default=None)
    """
    Full test results (fetched from cloud storage, populated on GET)
    """

    created_at: dt.datetime = pydantic.Field()
    """
    When evaluation run was created
    """

    started_at: typing.Optional[dt.datetime] = pydantic.Field(default=None)
    """
    When execution started
    """

    completed_at: typing.Optional[dt.datetime] = pydantic.Field(default=None)
    """
    When execution completed
    """

    duration_ms: typing.Optional[int] = pydantic.Field(default=None)
    """
    Total execution time
    """

    tags: typing.Optional[typing.List[str]] = pydantic.Field(default=None)
    """
    Tags for organization (inherited from config + run-specific)
    """

    metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = pydantic.Field(default=None)
    """
    Additional custom metadata
    """

    organization_id: str = pydantic.Field()
    """
    Organization that owns this evaluation run
    """

    created_by: typing.Optional[str] = pydantic.Field(default=None)
    """
    User who created evaluation run
    """

    baseline_run_id: typing.Optional[str] = pydantic.Field(default=None)
    """
    Compare results against this baseline run
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
